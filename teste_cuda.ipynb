{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80fbdfe-efe1-4b08-ab01-5b0abb9851ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import cuml as cm\n",
    "import cupy as cp\n",
    "import cudf as cd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import lightgbm as lgb\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242349e4-1e06-442f-8f0c-40304ac8a8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>gender_identity</th>\n",
       "      <th>sexual_orientation</th>\n",
       "      <th>bmi</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>student_accommodation</th>\n",
       "      <th>work</th>\n",
       "      <th>income_grupos de referência pelo percentil_20,40,60,80,100</th>\n",
       "      <th>score_food_smile</th>\n",
       "      <th>score_subs_smile</th>\n",
       "      <th>score_Physical Activity_smile</th>\n",
       "      <th>score_stress_smile</th>\n",
       "      <th>score_social_smile</th>\n",
       "      <th>score_sleep_smile</th>\n",
       "      <th>score_envir_smile</th>\n",
       "      <th>sedentary_behavior</th>\n",
       "      <th>sedentary_2</th>\n",
       "      <th>gad7_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7377.000000</td>\n",
       "      <td>7366.000000</td>\n",
       "      <td>7318.000000</td>\n",
       "      <td>7343.000000</td>\n",
       "      <td>7029.000000</td>\n",
       "      <td>7358.000000</td>\n",
       "      <td>7364.000000</td>\n",
       "      <td>7353.000000</td>\n",
       "      <td>6622.000000</td>\n",
       "      <td>7369.000000</td>\n",
       "      <td>7307.000000</td>\n",
       "      <td>7330.000000</td>\n",
       "      <td>7343.000000</td>\n",
       "      <td>7329.000000</td>\n",
       "      <td>7342.000000</td>\n",
       "      <td>7342.000000</td>\n",
       "      <td>7370.000000</td>\n",
       "      <td>7373.000000</td>\n",
       "      <td>7377.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.779992</td>\n",
       "      <td>0.397231</td>\n",
       "      <td>0.034299</td>\n",
       "      <td>0.633256</td>\n",
       "      <td>23.386815</td>\n",
       "      <td>1.081136</td>\n",
       "      <td>0.979223</td>\n",
       "      <td>0.806610</td>\n",
       "      <td>1.959680</td>\n",
       "      <td>7.571584</td>\n",
       "      <td>14.865608</td>\n",
       "      <td>7.366712</td>\n",
       "      <td>3.880567</td>\n",
       "      <td>12.844999</td>\n",
       "      <td>9.485835</td>\n",
       "      <td>8.605148</td>\n",
       "      <td>2.034600</td>\n",
       "      <td>1.119626</td>\n",
       "      <td>0.449641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.087655</td>\n",
       "      <td>0.489358</td>\n",
       "      <td>0.182009</td>\n",
       "      <td>1.048884</td>\n",
       "      <td>4.493129</td>\n",
       "      <td>0.538142</td>\n",
       "      <td>0.142646</td>\n",
       "      <td>0.394983</td>\n",
       "      <td>1.418598</td>\n",
       "      <td>1.590574</td>\n",
       "      <td>1.610601</td>\n",
       "      <td>2.548647</td>\n",
       "      <td>1.546530</td>\n",
       "      <td>4.821286</td>\n",
       "      <td>4.571043</td>\n",
       "      <td>2.096251</td>\n",
       "      <td>1.015164</td>\n",
       "      <td>1.079484</td>\n",
       "      <td>0.497491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.818459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.312500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.666666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.461981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex  gender_identity  sexual_orientation  \\\n",
       "count  7377.000000  7366.000000      7318.000000         7343.000000   \n",
       "mean     19.779992     0.397231         0.034299            0.633256   \n",
       "std       3.087655     0.489358         0.182009            1.048884   \n",
       "min      16.000000     0.000000         0.000000            0.000000   \n",
       "25%      18.000000     0.000000         0.000000            0.000000   \n",
       "50%      19.000000     0.000000         0.000000            0.000000   \n",
       "75%      20.000000     1.000000         0.000000            1.000000   \n",
       "max      35.000000     1.000000         1.000000            4.000000   \n",
       "\n",
       "               bmi  marital_status  student_accommodation         work  \\\n",
       "count  7029.000000     7358.000000            7364.000000  7353.000000   \n",
       "mean     23.386815        1.081136               0.979223     0.806610   \n",
       "std       4.493129        0.538142               0.142646     0.394983   \n",
       "min      12.818459        0.000000               0.000000     0.000000   \n",
       "25%      20.312500        1.000000               1.000000     1.000000   \n",
       "50%      22.666666        1.000000               1.000000     1.000000   \n",
       "75%      25.461981        1.000000               1.000000     1.000000   \n",
       "max      65.000000        4.000000               1.000000     1.000000   \n",
       "\n",
       "       income_grupos de referência pelo percentil_20,40,60,80,100  \\\n",
       "count                                        6622.000000            \n",
       "mean                                            1.959680            \n",
       "std                                             1.418598            \n",
       "min                                             0.000000            \n",
       "25%                                             1.000000            \n",
       "50%                                             2.000000            \n",
       "75%                                             3.000000            \n",
       "max                                             4.000000            \n",
       "\n",
       "       score_food_smile  score_subs_smile  score_Physical Activity_smile  \\\n",
       "count       7369.000000       7307.000000                    7330.000000   \n",
       "mean           7.571584         14.865608                       7.366712   \n",
       "std            1.590574          1.610601                       2.548647   \n",
       "min            3.000000          4.000000                       3.000000   \n",
       "25%            6.000000         14.000000                       5.000000   \n",
       "50%            7.000000         15.000000                       7.000000   \n",
       "75%            9.000000         16.000000                       9.000000   \n",
       "max           12.000000         16.000000                      12.000000   \n",
       "\n",
       "       score_stress_smile  score_social_smile  score_sleep_smile  \\\n",
       "count         7343.000000         7329.000000        7342.000000   \n",
       "mean             3.880567           12.844999           9.485835   \n",
       "std              1.546530            4.821286           4.571043   \n",
       "min              2.000000            3.000000           3.000000   \n",
       "25%              3.000000            9.000000           6.000000   \n",
       "50%              4.000000           14.000000           8.000000   \n",
       "75%              5.000000           17.000000          12.000000   \n",
       "max              8.000000           20.000000          20.000000   \n",
       "\n",
       "       score_envir_smile  sedentary_behavior  sedentary_2   gad7_class  \n",
       "count        7342.000000         7370.000000  7373.000000  7377.000000  \n",
       "mean            8.605148            2.034600     1.119626     0.449641  \n",
       "std             2.096251            1.015164     1.079484     0.497491  \n",
       "min             4.000000            0.000000     0.000000     0.000000  \n",
       "25%             7.000000            1.000000     0.000000     0.000000  \n",
       "50%             9.000000            2.000000     1.000000     0.000000  \n",
       "75%            10.000000            3.000000     2.000000     1.000000  \n",
       "max            16.000000            4.000000     4.000000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"América do Sul_MOD.xlsx\", sheet_name='Sheet1')\n",
    "\n",
    "cat_col_minus_oh = [\"sex\", \"student_accommodation\", \"work\", \n",
    "                    \"income_grupos de referência pelo percentil_20,40,60,80,100\",\n",
    "                    \"sedentary_behavior\", 'sedentary_2']\n",
    "\n",
    "one_hotted = [\"marital_status\", \"gender_identity\", \"sexual_orientation\", \"country_code\"]                \n",
    "target_col = \"gad7_class\"\n",
    "\n",
    "data = data.drop(columns=[\"continent_code\", \"country_code\"])\n",
    "\n",
    "X = data.drop(columns=[target_col])\n",
    "y = data[target_col]\n",
    "\n",
    "missing_data_idx = X[X.isna().any(axis=1)].index.to_numpy()\n",
    "complete_data_idx = X.dropna().index.to_numpy()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_excel(\"América do Sul_MODEL_treated.xlsx\", index=False)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592e4b0b-12d5-4931-ac96-c0ef602acd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: (4839, 30), Teste: (1210, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, ShuffleSplit\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "shuffle_split = ShuffleSplit(n_splits=5, test_size=0.2, random_state=50)\n",
    "splits = []\n",
    "\n",
    "one_hotted = [\"marital_status\", \"gender_identity\", \"sexual_orientation\", 'sex', 'student_accommodation', 'work']  \n",
    "\n",
    "#cat_noh = ['sex', 'student_accommodation', 'work', 'sedentary_behavior','sedentary_2','income_grupos de referência pelo percentil_20,40,60,80,100']\n",
    "\n",
    "num = ['age', 'bmi', 'score_food_smile', 'score_subs_smile', 'score_Physical Activity_smile',\n",
    "       'score_stress_smile', 'score_social_smile', 'score_sleep_smile',\n",
    "       'score_envir_smile',  'sedentary_behavior','sedentary_2',\n",
    "       'income_grupos de referência pelo percentil_20,40,60,80,100']\n",
    "\n",
    "for train_pos, test_pos in shuffle_split.split(complete_data_idx):\n",
    "    train_idx = complete_data_idx[train_pos]\n",
    "    test_idx = complete_data_idx[test_pos]\n",
    "\n",
    "#    train_idx = pd.Index(train_idx).union(missing_data_idx)  \n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # One-hot encoding e StandardScaler\n",
    "    onehot_transformer = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    #scaler_transformer = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler_transformer = StandardScaler()\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"onehot\", onehot_transformer, one_hotted),\n",
    "            (\"scaler\", scaler_transformer, num),\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    #  codficando e escalonando\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    \n",
    "    #nomeando as variáveis nos splits - melhor visualização\n",
    "    onehot_names = preprocessor.named_transformers_[\"onehot\"].get_feature_names_out(one_hotted)\n",
    "    scaled_names = num\n",
    "\n",
    "    remaining = [col for col in X_train.columns if col not in one_hotted + num]\n",
    "\n",
    "    all_feature_names = np.concatenate([onehot_names, scaled_names, remaining])\n",
    "\n",
    "    X_train = pd.DataFrame(X_train_transformed, index=X_train.index, columns=all_feature_names)\n",
    "    X_test = pd.DataFrame(X_test_transformed, index=X_test.index, columns=all_feature_names)\n",
    "\n",
    "    # guardando splits com os dados transformados\n",
    "    splits.append({\n",
    "        \"X_train\": X_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test\n",
    "    })\n",
    "\n",
    "# debugging: check do \"transformer\"\n",
    "print(f\"Treino: {splits[0]['X_train'].shape}, Teste: {splits[0]['X_test'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2b49e0-d304-4d66-8105-16a4761bc8f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=1)\n",
    "for split in splits:\n",
    "\n",
    "    X_train_imputed = pd.DataFrame(\n",
    "        knn_imputer.fit_transform(split[\"X_train\"]),\n",
    "        columns=split[\"X_train\"].columns,\n",
    "        index=split[\"X_train\"].index\n",
    "    )\n",
    "\n",
    "    split[\"X_train_imputed\"] = X_train_imputed\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083957c5-95f4-4fe9-9873-7aa18414f4b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "c2 = ['marital_status_0.0', 'marital_status_1.0', 'marital_status_2.0',\n",
    "       'marital_status_3.0', 'marital_status_4.0', 'marital_status_nan',\n",
    "       'gender_identity_0.0', 'gender_identity_1.0', 'gender_identity_nan',\n",
    "       'sexual_orientation_0.0', 'sexual_orientation_1.0',\n",
    "       'sexual_orientation_2.0', 'sexual_orientation_3.0',\n",
    "       'sexual_orientation_4.0', 'sexual_orientation_nan', \"sex_0.0\",\t\"sex_1.0\",\t\"sex_nan\",\t\"student_accommodation_0.0\",\t\n",
    "       \"student_accommodation_1.0\",\t\"student_accommodation_nan\",\t\"work_0.0\",\t\"work_1.0\",\t\"work_nan\"] \n",
    "\n",
    "ks = ['age', 'bmi', 'income_grupos de referência pelo percentil_20,40,60,80,100', \n",
    "      'score_food_smile', 'score_subs_smile', 'score_Physical Activity_smile',\n",
    "      'score_stress_smile', 'score_social_smile', 'score_sleep_smile',\n",
    "      'score_envir_smile', 'sedentary_behavior','sedentary_2']\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "\n",
    "    X_train_imputed = splits[i][\"X_train_imputed\"]\n",
    "\n",
    "    #testando a similaridade dos dados inputados vs originais\n",
    "    for col in split[\"X_train\"].columns:\n",
    "        #teste KS para variáveis numéricas\n",
    "        if col in ks:\n",
    "            original_values = split[\"X_train\"][col].dropna()\n",
    "            imputed_values = X_train_imputed[col]\n",
    "\n",
    "            ks_stat, p_value = ks_2samp(original_values, imputed_values)\n",
    "\n",
    "            if p_value < 0.05: print(f\"Variável {col}  NÃO tem distribuições similares (failed null-hypothesis) - {p_value}\")\n",
    "            #else: print(f\"Variável {col} NÃO tem distribuições similares (proved null-hypothesis) - {p_value}\")\n",
    "\n",
    "        #chi-quadrado para testar variação entre categóricas\n",
    "        elif col in c2:\n",
    "            original_counts = split[\"X_train\"][col].value_counts()\n",
    "            imputed_counts = X_train_imputed[col].round().astype(int).value_counts()\n",
    "\n",
    "            original_counts= original_counts.reindex(imputed_counts.index, fill_value=0)\n",
    "            imputed_counts= imputed_counts.reindex(original_counts.index, fill_value=0)\n",
    "\n",
    "            chi2, p_value, _, _ = chi2_contingency([original_counts, imputed_counts])\n",
    "\n",
    "            if p_value < 0.05: print(f\"Variável {col} AFETADA pela inputação (failed null-hypothesis) - {p_value}\")\n",
    "            #else: print(f\"Variável {col} AFETADA pela inputação (proved null-hypothesis) - {p_value}\")\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a12a8a1a-09a1-4b85-9869-0452b3cb75ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n",
      "  return init_func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 -- Accuracy: 0.702, Recall: 0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n",
      "  return init_func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2 -- Accuracy: 0.674, Recall: 0.670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n",
      "  return init_func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 3 -- Accuracy: 0.675, Recall: 0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n",
      "  return init_func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 4 -- Accuracy: 0.663, Recall: 0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n",
      "  return init_func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 5 -- Accuracy: 0.680, Recall: 0.676\n",
      "\n",
      "Overall Cross-Validation Metrics:\n",
      "Average Accuracy: 0.679\n",
      "Average Recall: 0.674\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from cuml.ensemble import RandomForestClassifier as cuRFClassifier\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "import shap\n",
    "\n",
    "acc_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "f1_beta_list = []\n",
    "all_y_true = []\n",
    "all_predictions = []\n",
    "all_shap_values = []\n",
    "\n",
    "smote = SMOTE(random_state=42, sampling_strategy='minority', k_neighbors=1)\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    \n",
    "    X_train_cudf = cudf.DataFrame(split['X_train_imputed'])\n",
    "    X_test_cudf = cudf.DataFrame(split['X_test'])\n",
    "    y_train_cudf = cudf.Series(split['y_train'])\n",
    "    y_test_cudf = cudf.Series(split['y_test'])\n",
    "    \n",
    "    clf_rf = cuRFClassifier(\n",
    "        n_estimators=130,\n",
    "        max_depth=14,\n",
    "        min_samples_leaf=3,\n",
    "        max_features='sqrt',\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_streams=2.4\n",
    "    )\n",
    "\n",
    "    clf_rf.fit(X_train_cudf, y_train_cudf)\n",
    "    predictions = clf_rf.predict(X_test_cudf)\n",
    "    \n",
    "    predictions_host = predictions.to_numpy() if hasattr(predictions, \"to_numpy\") else np.array(predictions)\n",
    "    y_test_host = y_test_cudf.to_numpy() if hasattr(y_test_cudf, \"to_numpy\") else np.array(y_test_cudf)\n",
    "    \n",
    "    acc = accuracy_score(y_test_host, predictions_host)\n",
    "    recall = recall_score(y_test_host, predictions_host, average='macro')\n",
    "    \n",
    "    print(f\"Split {i+1} -- Accuracy: {acc:.3f}, Recall: {recall:.3f}\")\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    recall_list.append(recall)\n",
    "    all_y_true.extend(y_test_host)\n",
    "    all_predictions.extend(predictions_host)\n",
    "    \n",
    "#   explainer = shap.explainers.GPUTree(clf_rf)\n",
    "#   s#hap_values = explainer.shap_values(X_test_cudf.to_numpy(), check_additivity=False)\n",
    "#   for SHAPs in shap_values:\n",
    "#       all_shap_values.append(SHAPs)\n",
    "    \n",
    "avg_acc = np.mean(acc_list)\n",
    "avg_recall = np.mean(recall_list)\n",
    "\n",
    "print(\"\\nOverall Cross-Validation Metrics:\")\n",
    "print(\"Average Accuracy: {:.3f}\".format(avg_acc))\n",
    "print(\"Average Recall: {:.3f}\".format(avg_recall))\n",
    "\n",
    "#columns = splits[0][\"X_train_imputed\"].columns\n",
    "#X_test = pd.DataFrame(X_test, columns=columns)\n",
    "#X_test.rename(columns={'income_grupos de referência pelo percentil_20,40,60,80,100': 'income_pct'}, inplace=True)\n",
    "#\n",
    "#shap_df = cudf.DataFrame(shap_values[:, :, 1], columns = X_test.columns)\n",
    "#shap_df_agg = shap_df.groupby(one_hot_agg, axis=1).sum()\n",
    "#X_test_agg = X_test.groupby(one_hot_agg, axis=1).first()\n",
    "#\n",
    "#shap_df_aggregated = shap_df_agg.groupby(aggregate_col, axis=1).sum()\n",
    "#X_test_aggregated = X_test_agg.groupby(aggregate_col, axis=1).first()\n",
    "#\n",
    "#shap.summary_plot(shap_df_aggregated.values, X_test_aggregated, max_display=50, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8fb0ee7-5a88-455a-8c28-faf5f02fe5bf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n",
      " -- Train Accuracy x Test Accuracy: 0.897 x 0.702\n",
      " -- Train Recall x Test Recall: 0.897 x 0.702\n",
      " -- Train ROC AUC x Test ROC AUC: 0.965 x 0.776\n",
      "Split 2\n",
      " -- Train Accuracy x Test Accuracy: 0.888 x 0.677\n",
      " -- Train Recall x Test Recall: 0.889 x 0.677\n",
      " -- Train ROC AUC x Test ROC AUC: 0.963 x 0.731\n",
      "Split 3\n",
      " -- Train Accuracy x Test Accuracy: 0.885 x 0.682\n",
      " -- Train Recall x Test Recall: 0.885 x 0.681\n",
      " -- Train ROC AUC x Test ROC AUC: 0.962 x 0.746\n",
      "Split 4\n",
      " -- Train Accuracy x Test Accuracy: 0.889 x 0.665\n",
      " -- Train Recall x Test Recall: 0.889 x 0.662\n",
      " -- Train ROC AUC x Test ROC AUC: 0.961 x 0.727\n",
      "Split 5\n",
      " -- Train Accuracy x Test Accuracy: 0.881 x 0.674\n",
      " -- Train Recall x Test Recall: 0.882 x 0.674\n",
      " -- Train ROC AUC x Test ROC AUC: 0.961 x 0.742\n",
      "Split 6\n",
      " -- Train Accuracy x Test Accuracy: 0.895 x 0.686\n",
      " -- Train Recall x Test Recall: 0.895 x 0.685\n",
      " -- Train ROC AUC x Test ROC AUC: 0.966 x 0.741\n",
      "Split 7\n",
      " -- Train Accuracy x Test Accuracy: 0.889 x 0.693\n",
      " -- Train Recall x Test Recall: 0.888 x 0.691\n",
      " -- Train ROC AUC x Test ROC AUC: 0.963 x 0.760\n",
      "Split 8\n",
      " -- Train Accuracy x Test Accuracy: 0.883 x 0.674\n",
      " -- Train Recall x Test Recall: 0.884 x 0.673\n",
      " -- Train ROC AUC x Test ROC AUC: 0.961 x 0.733\n",
      "Split 9\n",
      " -- Train Accuracy x Test Accuracy: 0.892 x 0.695\n",
      " -- Train Recall x Test Recall: 0.891 x 0.695\n",
      " -- Train ROC AUC x Test ROC AUC: 0.962 x 0.754\n",
      "Split 10\n",
      " -- Train Accuracy x Test Accuracy: 0.891 x 0.679\n",
      " -- Train Recall x Test Recall: 0.891 x 0.676\n",
      " -- Train ROC AUC x Test ROC AUC: 0.962 x 0.746\n",
      "\n",
      "Overall Cross-Validation Metrics:\n",
      "Average Accuracy: 0.889 x 0.683\n",
      "Average Recall: 0.889 x 0.682\n",
      "Average AUC-SCORE: 0.963 x 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501/4106542944.py:133: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  shap_df_agg = shap_df.groupby(one_hot_agg, axis=1).sum()\n",
      "/tmp/ipykernel_501/4106542944.py:134: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  X_test_agg = X_test.groupby(one_hot_agg, axis=1).first()\n",
      "/tmp/ipykernel_501/4106542944.py:136: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  shap_df_aggregated = shap_df_agg.groupby(aggregate_col, axis=1).sum()\n",
      "/tmp/ipykernel_501/4106542944.py:137: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  X_test_aggregated = X_test_agg.groupby(aggregate_col, axis=1).first()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x310 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RandomForest - teste sem imputação/balanceamento\n",
    "one_hotted = [\"marital_status\", \"gender_identity\", \"sexual_orientation\", \n",
    "              \"country_code\", 'sex', 'student_accommodation', 'work'] \n",
    "\n",
    "lifestyle = ['score_subs_smile', 'score_Physical Activity_smile', 'score_stress_smile', \n",
    "             'score_social_smile', 'score_sleep_smile','score_envir_smile', 'score_food_smile']\n",
    "\n",
    "social_var = [\"marital_status\", \"gender_identity\", \"sexual_orientation\", \n",
    "              'sex', 'student_accommodation', 'work', 'income_pct', 'sedentary_behavior' , 'sedentary_2']\n",
    "\n",
    "def one_hot_agg(name):\n",
    "    for prefix in one_hotted:\n",
    "        if name.startswith(prefix):\n",
    "            return prefix\n",
    "    return name\n",
    "\n",
    "def aggregate_col(col):\n",
    "    if col in lifestyle:\n",
    "        return 'lifestyle'\n",
    "    elif col in social_var:\n",
    "        return 'social_var'\n",
    "    else:\n",
    "        return col\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, fbeta_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "acc_train_list,  acc_test_list = [], []\n",
    "recall_train_list, recall_test_list = [], []\n",
    "roc_auc_train_list, roc_auc_test_list = [], []\n",
    "all_y_true = []\n",
    "all_predictions = []\n",
    "all_shap_values = []\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    \n",
    "    X_train = split[\"X_train\"]\n",
    "    X_test = split['X_test']\n",
    "    y_train = split[\"y_train\"]\n",
    "    y_test = split['y_test']\n",
    "    \n",
    "#    columns = splits[0][\"X_test\"].columns\n",
    "#    X_test = pd.DataFrame(X_test, columns=columns)\n",
    "#    X_test.rename(columns={'income_grupos de referência pelo percentil_20,40,60,80,100': 'income_pct'}, inplace=True)\n",
    "\n",
    "#   escrevi aqui os valores dos hiperparametros que utilizei, mais para guardar um histórico\n",
    "#   GridSearch 1: (max_depth=10, min_samples_split=10, n_estimators=200) - 0.422\n",
    "\n",
    "    clf_rf = RandomForestClassifier(\n",
    "                                    n_estimators=150,\n",
    "                                    max_depth=None,\n",
    "                                    min_samples_split=5,\n",
    "                                    min_samples_leaf=4,\n",
    "                                    max_features='sqrt',\n",
    "                                    class_weight='balanced',\n",
    "                                    criterion='entropy',\n",
    "                                    bootstrap=True)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    \n",
    "    pred_test = clf_rf.predict(X_test)\n",
    "    pred_train = clf_rf.predict(X_train)\n",
    "    \n",
    "    y_train_pred_prob = clf_rf.predict_proba(X_train)[:, 1]\n",
    "    y_test_pred_prob = clf_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc_test = accuracy_score(y_test, pred_test)\n",
    "    acc_train = accuracy_score(y_train, pred_train)\n",
    "    \n",
    "    recall_test = recall_score(y_test, pred_test, average='macro')\n",
    "    recall_train = recall_score(y_train, pred_train, average='macro')\n",
    "    \n",
    "    #f1 = f1_score(y_test, predictions, average='macro')\n",
    "    #f1_beta = fbeta_score(y_test, predictions, beta=0.5, average='macro')\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    #print(f\"Split {i+1} -- Accuracy: {acc:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}, F1-beta: {f1_beta:.3f}, ROC-AUC: {roc_auc:.3f}\")\n",
    "    print(f\"Split {i+1}\")\n",
    "    print(f\" -- Train Accuracy x Test Accuracy: {acc_train:.3f} x {acc_test:.3f}\")\n",
    "    print(f\" -- Train Recall x Test Recall: {recall_train:.3f} x {recall_test:.3f}\")\n",
    "    print(f\" -- Train ROC AUC x Test ROC AUC: {train_auc:.3f} x {test_auc:.3f}\")\n",
    "\n",
    "    acc_test_list.append(acc_test)\n",
    "    acc_train_list.append(acc_train)\n",
    "    recall_test_list.append(recall_test)\n",
    "    recall_train_list.append(recall_train)\n",
    "    #f1_list.append(f1)\n",
    "    #f1_beta_list.append(f1_beta)\n",
    "    roc_auc_test_list.append(test_auc)\n",
    "    roc_auc_train_list.append(train_auc)\n",
    "    \n",
    "#    all_y_true.extend(y_test)\n",
    "#    all_predictions.extend(predictions)\n",
    "\n",
    "    explainer = shap.TreeExplainer(clf_rf)\n",
    "    shap_values = explainer.shap_values(X_test, check_additivity=False)\n",
    "    for SHAPs in shap_values:\n",
    "        all_shap_values.append(SHAPs)\n",
    "\n",
    "avg_acc_train, avg_acc_test = np.mean(acc_train_list), np.mean(acc_test_list)\n",
    "avg_recall_train, avg_recall_test = np.mean(recall_train_list), np.mean(recall_test_list)\n",
    "#avg_f1 = np.mean(f1_list)\n",
    "#avg_f1_beta = np.mean(f1_beta_list)\n",
    "avg_roc_auc_score_train, avg_roc_auc_score_test = np.mean(roc_auc_train_list), np.mean(roc_auc_test_list)\n",
    "\n",
    "print(\"\\nOverall Cross-Validation Metrics:\")\n",
    "print(f\"Average Accuracy: {avg_acc_train:.3f} x {avg_acc_test:.3f}\")\n",
    "print(f\"Average Recall: {avg_recall_train:.3f} x {avg_recall_test:.3f}\")\n",
    "print(f\"Average AUC-SCORE: {avg_roc_auc_score_train:.3f} x {avg_roc_auc_score_test:.3f}\")\n",
    "          \n",
    "#print(\"Average Recall: {:.3f}\".format(avg_recall))\n",
    "#print(\"Average F1 Score: {:.3f}\".format(avg_f1))\n",
    "#print(\"Average F1-beta Score: {:.3f}\".format(avg_f1_beta))\n",
    "#print(\"Average ROC-AUC score: {:.3f}\".format(avg_roc_auc_score))\n",
    "\n",
    "## Compute and display the overall confusion matrix\n",
    "#cm = confusion_matrix(all_y_true, all_predictions, labels=clf_rf.classes_)\n",
    "#mtx = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_rf.classes_)\n",
    "#mtx.plot(cmap=\"YlGnBu\")\n",
    "#plt.show()\n",
    "\n",
    "columns = splits[0][\"X_train_imputed\"].columns\n",
    "X_test = pd.DataFrame(X_test, columns=columns)\n",
    "X_test.rename(columns={'income_grupos de referência pelo percentil_20,40,60,80,100': 'income_pct'}, inplace=True)\n",
    "\n",
    "shap_df = pd.DataFrame(shap_values[:, :, 1], columns = X_test.columns)\n",
    "shap_df_agg = shap_df.groupby(one_hot_agg, axis=1).sum()\n",
    "X_test_agg = X_test.groupby(one_hot_agg, axis=1).first()\n",
    "\n",
    "shap_df_aggregated = shap_df_agg.groupby(aggregate_col, axis=1).sum()\n",
    "X_test_aggregated = X_test_agg.groupby(aggregate_col, axis=1).first()\n",
    "\n",
    "# Now call the SHAP summary plot with matching shapes:\n",
    "shap.summary_plot(shap_df_agg.values, X_test_agg, max_display=50, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a21b6dcb-0a95-4689-bebb-2edf2c761a41",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 -- Accuracy: 0.695, Recall: 0.691, F1: 0.691, F1-beta: 0.691\n",
      "Split 2 -- Accuracy: 0.674, Recall: 0.671, F1: 0.670, F1-beta: 0.670\n",
      "Split 3 -- Accuracy: 0.675, Recall: 0.674, F1: 0.673, F1-beta: 0.673\n",
      "Split 4 -- Accuracy: 0.672, Recall: 0.669, F1: 0.669, F1-beta: 0.669\n",
      "Split 5 -- Accuracy: 0.688, Recall: 0.685, F1: 0.686, F1-beta: 0.686\n",
      "Split 6 -- Accuracy: 0.678, Recall: 0.676, F1: 0.676, F1-beta: 0.676\n",
      "Split 7 -- Accuracy: 0.688, Recall: 0.686, F1: 0.686, F1-beta: 0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "one_hotted = [\"marital_status\", \"gender_identity\", \"sexual_orientation\", \n",
    "              \"country_code\", 'sex', 'student_accommodation', 'work'] \n",
    "\n",
    "lifestyle = ['score_subs_smile', 'score_Physical Activity_smile', 'score_stress_smile', \n",
    "             'score_social_smile', 'score_sleep_smile','score_envir_smile', 'score_food_smile']\n",
    "\n",
    "social_var = [\"marital_status\", \"gender_identity\", \"sexual_orientation\", \n",
    "              'sex', 'student_accommodation', 'work', 'income_pct', 'sedentary_behavior' , 'sedentary_2']\n",
    "\n",
    "def one_hot_agg(name):\n",
    "    for prefix in one_hotted:\n",
    "        if name.startswith(prefix):\n",
    "            return prefix\n",
    "    return name\n",
    "\n",
    "def aggregate_col(col):\n",
    "    if col in lifestyle:\n",
    "        return 'lifestyle'\n",
    "    elif col in social_var:\n",
    "        return 'social_var'\n",
    "    else:\n",
    "        return col\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, fbeta_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, cross_val_predict\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "smote = SMOTE(random_state=42, sampling_strategy='minority', k_neighbors=1)\n",
    "\n",
    "acc_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "f1_beta_list = []\n",
    "all_y_true = []\n",
    "all_predictions = []\n",
    "all_shap_values = []\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "\n",
    "    X_train = split['X_train_imputed']\n",
    "    X_test = split['X_test']\n",
    "    y_train = split['y_train']\n",
    "    y_test = split['y_test']\n",
    "\n",
    "    X_train_rs, y_train_rs = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #print(\"Distribuição de treino original:\", np.bincount(y_train))\n",
    "    #print(\"Distribuição de treino com resample\", np.bincount(y_train_rs))\n",
    "    \n",
    "#    columns = splits[0][\"X_test\"].columns\n",
    "#    X_test = pd.DataFrame(X_test, columns=columns)\n",
    "#    X_test.rename(columns={'income_grupos de referência pelo percentil_20,40,60,80,100': 'income_pct'}, inplace=True)\n",
    "\n",
    "#   escrevi aqui os valores dos hiperparametros que utilizei, mais para guardar um histórico\n",
    "#   GridSearch 1: (max_depth=10, min_samples_split=10, n_estimators=200) - 0.422\n",
    "\n",
    "    clf_rf = RandomForestClassifier(\n",
    "                                    n_estimators=150,\n",
    "                                    max_depth=None,\n",
    "                                    min_samples_split=5,\n",
    "                                    min_samples_leaf=4,\n",
    "                                    max_features='sqrt',\n",
    "                                    criterion='entropy',\n",
    "                                    bootstrap=True)\n",
    "    clf_rf.fit(X_train_rs, y_train_rs)\n",
    "    predictions = clf_rf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions, average='macro')\n",
    "    f1 = f1_score(y_test, predictions, average='macro')\n",
    "    f1_beta = fbeta_score(y_test, predictions, beta=0.5, average='macro')\n",
    "    \n",
    "    print(f\"Split {i+1} -- Accuracy: {acc:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}, F1-beta: {f1_beta:.3f}\")\n",
    "\n",
    "    acc_list.append(acc)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    f1_beta_list.append(f1_beta)\n",
    "    \n",
    "    all_y_true.extend(y_test)\n",
    "    all_predictions.extend(predictions)\n",
    "\n",
    "    explainer = shap.TreeExplainer(clf_rf)\n",
    "    shap_values = explainer.shap_values(X_test, check_additivity=False)\n",
    "    for SHAPs in shap_values:\n",
    "        all_shap_values.append(SHAPs)\n",
    "\n",
    "avg_acc = np.mean(acc_list)\n",
    "avg_recall = np.mean(recall_list)\n",
    "avg_f1 = np.mean(f1_list)\n",
    "avg_f1_beta = np.mean(f1_beta_list)\n",
    "\n",
    "print(\"\\nOverall Cross-Validation Metrics:\")\n",
    "print(\"Average Accuracy: {:.3f}\".format(avg_acc))\n",
    "print(\"Average Recall: {:.3f}\".format(avg_recall))\n",
    "print(\"Average F1 Score: {:.3f}\".format(avg_f1))\n",
    "print(\"Average F1-beta Score: {:.3f}\".format(avg_f1_beta))\n",
    "\n",
    "## Compute and display the overall confusion matrix\n",
    "#cm = confusion_matrix(all_y_true, all_predictions, labels=clf_rf.classes_)\n",
    "#mtx = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_rf.classes_)\n",
    "#mtx.plot(cmap=\"YlGnBu\")\n",
    "#plt.show()\n",
    "\n",
    "columns = splits[0][\"X_train_imputed\"].columns\n",
    "X_test = pd.DataFrame(X_test, columns=columns)\n",
    "X_test.rename(columns={'income_grupos de referência pelo percentil_20,40,60,80,100': 'income_pct'}, inplace=True)\n",
    "\n",
    "shap_df = pd.DataFrame(shap_values[:, :, 1], columns = X_test.columns)\n",
    "shap_df_agg = shap_df.groupby(one_hot_agg, axis=1).sum()\n",
    "X_test_agg = X_test.groupby(one_hot_agg, axis=1).first()\n",
    "\n",
    "shap_df_aggregated = shap_df_agg.groupby(aggregate_col, axis=1).sum()\n",
    "X_test_aggregated = X_test_agg.groupby(aggregate_col, axis=1).first()\n",
    "\n",
    "# Now call the SHAP summary plot with matching shapes:\n",
    "shap.summary_plot(shap_df_agg.values, X_test_agg, max_display=50, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7502239f-305a-4e15-90e5-02e953e455bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 2225, number of negative: 2614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDA=1\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "CUDA Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_CUDA=1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLightGBMError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     31\u001b[39m colsample = np.sqrt(n_features) / n_features\n\u001b[32m     33\u001b[39m model = lgb.LGBMClassifier(\n\u001b[32m     34\u001b[39m     n_estimators=\u001b[32m130\u001b[39m,\n\u001b[32m     35\u001b[39m     max_depth=\u001b[32m14\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     40\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m predictions = model.predict(X_test_df)\n\u001b[32m     45\u001b[39m acc = accuracy_score(y_test_np, predictions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/lightgbm/sklearn.py:1560\u001b[39m, in \u001b[36mLGBMClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1557\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1558\u001b[39m             valid_sets.append((valid_x, \u001b[38;5;28mself\u001b[39m._le.transform(valid_y)))\n\u001b[32m-> \u001b[39m\u001b[32m1560\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1574\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1575\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/lightgbm/engine.py:297\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     booster = \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[32m    299\u001b[39m         booster.set_train_data_name(train_data_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/lightgbm/basic.py:3660\u001b[39m, in \u001b[36mBooster.__init__\u001b[39m\u001b[34m(self, params, train_set, model_file, model_str)\u001b[39m\n\u001b[32m   3658\u001b[39m params.update(train_set.get_params())\n\u001b[32m   3659\u001b[39m params_str = _param_dict_to_str(params)\n\u001b[32m-> \u001b[39m\u001b[32m3660\u001b[39m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3661\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterCreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3663\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3665\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3666\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3667\u001b[39m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[32m   3668\u001b[39m \u001b[38;5;28mself\u001b[39m.train_set = train_set\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/lightgbm/basic.py:313\u001b[39m, in \u001b[36m_safe_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[32m    306\u001b[39m \n\u001b[32m    307\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    The return value from C API calls.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB.LGBM_GetLastError().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mLightGBMError\u001b[39m: CUDA Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_CUDA=1"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from cuml.ensemble import RandomForestClassifier as cuRFClassifier\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "import shap\n",
    "\n",
    "acc_list = []\n",
    "recall_list = []\n",
    "all_y_true = []\n",
    "all_predictions = []\n",
    "all_shap_values = []\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "\n",
    "    X_train_df = pd.DataFrame(split[\"X_train_imputed\"])\n",
    "    X_test_df = pd.DataFrame(split['X_test'])\n",
    "    y_train_np = np.array(split[\"y_train\"])\n",
    "    y_test_np = np.array(split['y_test'])\n",
    "    \n",
    "    X_train_cudf = cudf.DataFrame(split['X_train_imputed'])\n",
    "    X_test_cudf = cudf.DataFrame(split['X_test'])\n",
    "    y_train_cudf = cudf.Series(split['y_train'])\n",
    "    y_test_cudf = cudf.Series(split['y_test'])\n",
    "\n",
    "    X_train_df.columns = X_train.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "    X_test_df.columns = X_test.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "\n",
    "    n_features = X_train_df.shape[1]\n",
    "    colsample = np.sqrt(n_features) / n_features\n",
    "    \n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=130,\n",
    "        max_depth=14,\n",
    "        min_child_samples=3,\n",
    "        colsample_bytree=colsample,\n",
    "        random_state=42,\n",
    "        device='cuda'\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_df, y_train_np)\n",
    "    predictions = model.predict(X_test_df)\n",
    "    \n",
    "    acc = accuracy_score(y_test_np, predictions)\n",
    "    recall = recall_score(y_test_np, predictions, average='macro')\n",
    "    \n",
    "    print(f\"Split {i+1} -- Accuracy: {acc:.3f}, Recall: {recall:.3f}\")\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    recall_list.append(recall)\n",
    "    all_y_true.extend(y_test_np)\n",
    "    all_predictions.extend(predictions)\n",
    "\n",
    "    explainer = shap.explainers.GPUTree(model)\n",
    "    shap_values = explainer.shap_values(X_test_df.to_numpy(), check_additivity=False)\n",
    "    for SHAPs in shap_values:\n",
    "        all_shap_values.append(SHAPs)\n",
    "\n",
    "avg_acc = np.mean(acc_list)\n",
    "avg_recall = np.mean(recall_list)\n",
    "\n",
    "print(\"\\nOverall Cross-Validation Metrics:\")\n",
    "print(\"Average Accuracy: {:.3f}\".format(avg_acc))\n",
    "print(\"Average Recall: {:.3f}\".format(avg_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4ac235-ccf6-4e16-a161-da3defd034d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m preds.to_array() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(preds, \u001b[33m'\u001b[39m\u001b[33mto_array\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m preds    \n\u001b[32m     42\u001b[39m param_space = {\n\u001b[32m     43\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m100\u001b[39m, \u001b[32m125\u001b[39m, \u001b[32m150\u001b[39m, \u001b[32m175\u001b[39m, \u001b[32m200\u001b[39m],\n\u001b[32m     44\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m10\u001b[39m, \u001b[32m15\u001b[39m, \u001b[32m20\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_streams\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m],\n\u001b[32m     49\u001b[39m         }\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43msplits\u001b[49m):\n\u001b[32m     52\u001b[39m     X_train = split[\u001b[33m'\u001b[39m\u001b[33mX_train_imputed\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     53\u001b[39m     y_train = split[\u001b[33m'\u001b[39m\u001b[33my_train\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'splits' is not defined"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "recall_scorer = make_scorer(recall_score, average='macro')\n",
    "recall_scores = []\n",
    "best_params_list = []\n",
    "\n",
    "class cuMLWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=185, max_depth=15, min_samples_leaf=4, max_features='log2', bootstrap=True, random_state=42, n_streams=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.random_state = random_state\n",
    "        self.n_streams=n_streams\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = cudf.DataFrame(X)\n",
    "        if isinstance(y, np.ndarray):\n",
    "            y = cudf.Series(y)\n",
    "        self.estimator = cuRFClassifier(n_estimators=self.n_estimators,\n",
    "                                        max_depth=self.max_depth,\n",
    "                                        random_state=self.random_state,\n",
    "                                        min_samples_leaf=self.min_samples_leaf,\n",
    "                                        max_features=self.max_features,\n",
    "                                        bootstrap=self.bootstrap,\n",
    "                                        n_streams=1,\n",
    "                                       )\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = cudf.DataFrame(X)\n",
    "        preds = self.estimator.predict(X)\n",
    "        return preds.to_array() if hasattr(preds, 'to_array') else preds    \n",
    "        \n",
    "param_space = {\n",
    "        'n_estimators': [100, 125, 150, 175, 200],\n",
    "        'max_depth': [10, 15, 20],\n",
    "        'min_samples_leaf': [1, 2, 3, 4],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'bootstrap': [True, False],\n",
    "        'n_streams': [1, 2, 4],\n",
    "        }\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    X_train = split['X_train_imputed']\n",
    "    y_train = split['y_train']\n",
    "    X_test = split['X_test']\n",
    "    y_test = split['y_test']\n",
    "    \n",
    "    bayes_cv = BayesSearchCV(\n",
    "        estimator=cuMLWrapper(random_state=42),\n",
    "        search_spaces=param_space,\n",
    "        cv=5,                            # 3-fold cross-validation\n",
    "        n_iter=10,                       # number of parameter settings to try\n",
    "        scoring=recall_scorer,              # or another scoring metric as needed\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    bayes_cv.fit(X_train, y_train)\n",
    "    best_params_list.append(bayes_cv.best_params_)\n",
    "    \n",
    "    predictions = bayes_cv.predict(X_test)\n",
    "    best_recall = recall_score(y_test, predictions, average='macro')\n",
    "    recall_scores.append(best_recall)\n",
    "    print(f\"Split {i+1} - Best Parameters: {bayes_cv.best_params_}, Recall: {best_recall:.3f}\")\n",
    "\n",
    "avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "print(f\"\\nOverall Average Recall: {avg_recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "256f5e97-3d44-48a5-8f68-b2269ca3ab79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 242, in _get_response_values\n",
      "    y_pred, pos_label = prediction_method(X), None\n",
      "                        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2726/3825820470.py\", line 39, in predict\n",
      "    preds = self.estimator.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/nvtx/nvtx.py\", line 122, in inner\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 416, in dispatch\n",
      "    return self.dispatch_func(func_name, gpu_func, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"base.pyx\", line 764, in cuml.internals.base.UniversalBase.dispatch_func\n",
      "  File \"randomforestclassifier.pyx\", line 648, in cuml.ensemble.randomforestclassifier.RandomForestClassifier.predict\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"randomforest_common.pyx\", line 424, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"fil.pyx\", line 1105, in cuml.fil.fil.ForestInference.load_using_treelite_handle\n",
      "  File \"fil.pyx\", line 572, in cuml.fil.fil.ForestInference_impl.load_using_treelite_handle\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/jvcha/miniconda3/envs/rapids-25.02/include/rmm/mr/device/cuda_memory_resource.hpp\n",
      "\n",
      "  warnings.warn(\n",
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/utils/_response.py\", line 242, in _get_response_values\n",
      "    y_pred, pos_label = prediction_method(X), None\n",
      "                        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2726/3825820470.py\", line 39, in predict\n",
      "    preds = self.estimator.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/nvtx/nvtx.py\", line 122, in inner\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 416, in dispatch\n",
      "    return self.dispatch_func(func_name, gpu_func, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"base.pyx\", line 764, in cuml.internals.base.UniversalBase.dispatch_func\n",
      "  File \"randomforestclassifier.pyx\", line 648, in cuml.ensemble.randomforestclassifier.RandomForestClassifier.predict\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"randomforest_common.pyx\", line 424, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"fil.pyx\", line 1105, in cuml.fil.fil.ForestInference.load_using_treelite_handle\n",
      "  File \"fil.pyx\", line 572, in cuml.fil.fil.ForestInference_impl.load_using_treelite_handle\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/jvcha/miniconda3/envs/rapids-25.02/include/rmm/mr/device/cuda_memory_resource.hpp\n",
      "\n",
      "  warnings.warn(\n",
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.64226897 0.64182328 0.64660662 0.6446497  0.64428725 0.64712812\n",
      " 0.64712812        nan 0.64231099 0.64837033 0.64523448 0.64586271\n",
      " 0.64793368 0.64159556 0.64325884 0.64614487 0.64670811 0.64508787\n",
      " 0.64486643 0.64168795]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 - Best Parameters: {'n_streams': 1, 'n_estimators': 100, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}, Recall: 0.696\n",
      "Split 2 - Best Parameters: {'n_streams': 2, 'n_estimators': 125, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}, Recall: 0.669\n",
      "Split 3 - Best Parameters: {'n_streams': 4, 'n_estimators': 175, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': True}, Recall: 0.683\n",
      "Split 4 - Best Parameters: {'n_streams': 4, 'n_estimators': 125, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}, Recall: 0.658\n",
      "Split 5 - Best Parameters: {'n_streams': 1, 'n_estimators': 125, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': False}, Recall: 0.664\n",
      "\n",
      "Overall Average Recall: 0.674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "recall_scorer = make_scorer(recall_score, average='macro')\n",
    "recall_scores = []\n",
    "best_params_list = []\n",
    "\n",
    "class cuMLWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=185, max_depth=15, min_samples_leaf=4, max_features='log2', bootstrap=True, random_state=42, n_streams=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.random_state = random_state\n",
    "        self.n_streams=n_streams\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = cudf.DataFrame(X)\n",
    "        if isinstance(y, np.ndarray):\n",
    "            y = cudf.Series(y)\n",
    "        self.estimator = cuRFClassifier(n_estimators=self.n_estimators,\n",
    "                                        max_depth=self.max_depth,\n",
    "                                        random_state=self.random_state,\n",
    "                                        min_samples_leaf=self.min_samples_leaf,\n",
    "                                        max_features=self.max_features,\n",
    "                                        bootstrap=self.bootstrap,\n",
    "                                        n_streams=1,\n",
    "                                       )\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = cudf.DataFrame(X)\n",
    "        preds = self.estimator.predict(X)\n",
    "        return preds.to_array() if hasattr(preds, 'to_array') else preds    \n",
    "        \n",
    "param_space = {\n",
    "        'n_estimators': [100, 125, 150, 175, 200],\n",
    "        'max_depth': [10, 15, 20],\n",
    "        'min_samples_leaf': [1, 2, 3, 4],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'bootstrap': [True, False],\n",
    "        'n_streams': [1, 2, 4],\n",
    "        }\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    X_train = split['X_train_imputed']\n",
    "    y_train = split['y_train']\n",
    "    X_test = split['X_test']\n",
    "    y_test = split['y_test']\n",
    "    \n",
    "    random_search_cv = RandomizedSearchCV(\n",
    "        estimator=cuMLWrapper(random_state=42),\n",
    "        param_distributions=param_space,\n",
    "        cv=10,                            # 3-fold cross-validation\n",
    "        n_iter=20,                       # number of parameter settings to try\n",
    "        scoring=recall_scorer,              # or another scoring metric as needed\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search_cv.fit(X_train, y_train)\n",
    "    best_params_list.append(random_search_cv.best_params_)\n",
    "    \n",
    "    predictions = random_search_cv.predict(X_test)\n",
    "    best_recall = recall_score(y_test, predictions, average='macro')\n",
    "    recall_scores.append(best_recall)\n",
    "    print(f\"Split {i+1} - Best Parameters: {random_search_cv.best_params_}, Recall: {best_recall:.3f}\")\n",
    "\n",
    "avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "print(f\"\\nOverall Average Recall: {avg_recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ae0d3-236a-4850-bc27-2e5216f6ed7d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/base.py\", line 572, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_4772/1199548088.py\", line 39, in predict\n",
      "    preds = self.estimator.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/nvtx/nvtx.py\", line 122, in inner\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 416, in dispatch\n",
      "    return self.dispatch_func(func_name, gpu_func, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"base.pyx\", line 764, in cuml.internals.base.UniversalBase.dispatch_func\n",
      "  File \"randomforestclassifier.pyx\", line 648, in cuml.ensemble.randomforestclassifier.RandomForestClassifier.predict\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"randomforest_common.pyx\", line 424, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"fil.pyx\", line 1105, in cuml.fil.fil.ForestInference.load_using_treelite_handle\n",
      "  File \"fil.pyx\", line 572, in cuml.fil.fil.ForestInference_impl.load_using_treelite_handle\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/jvcha/miniconda3/envs/rapids-25.02/include/rmm/mr/device/cuda_memory_resource.hpp\n",
      "\n",
      "  warnings.warn(\n",
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/base.py\", line 572, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_4772/1199548088.py\", line 39, in predict\n",
      "    preds = self.estimator.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/nvtx/nvtx.py\", line 122, in inner\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 416, in dispatch\n",
      "    return self.dispatch_func(func_name, gpu_func, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"base.pyx\", line 764, in cuml.internals.base.UniversalBase.dispatch_func\n",
      "  File \"randomforestclassifier.pyx\", line 648, in cuml.ensemble.randomforestclassifier.RandomForestClassifier.predict\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"randomforest_common.pyx\", line 424, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"fil.pyx\", line 1105, in cuml.fil.fil.ForestInference.load_using_treelite_handle\n",
      "  File \"fil.pyx\", line 572, in cuml.fil.fil.ForestInference_impl.load_using_treelite_handle\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/jvcha/miniconda3/envs/rapids-25.02/include/rmm/mr/device/cuda_memory_resource.hpp\n",
      "\n",
      "  warnings.warn(\n",
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/base.py\", line 572, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_4772/1199548088.py\", line 39, in predict\n",
      "    preds = self.estimator.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/nvtx/nvtx.py\", line 122, in inner\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 416, in dispatch\n",
      "    return self.dispatch_func(func_name, gpu_func, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"base.pyx\", line 764, in cuml.internals.base.UniversalBase.dispatch_func\n",
      "  File \"randomforestclassifier.pyx\", line 648, in cuml.ensemble.randomforestclassifier.RandomForestClassifier.predict\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"randomforest_common.pyx\", line 424, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"fil.pyx\", line 1105, in cuml.fil.fil.ForestInference.load_using_treelite_handle\n",
      "  File \"fil.pyx\", line 572, in cuml.fil.fil.ForestInference_impl.load_using_treelite_handle\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/jvcha/miniconda3/envs/rapids-25.02/include/rmm/mr/device/cuda_memory_resource.hpp\n",
      "\n",
      "  warnings.warn(\n",
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/base.py\", line 572, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_4772/1199548088.py\", line 39, in predict\n",
      "    preds = self.estimator.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/nvtx/nvtx.py\", line 122, in inner\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 416, in dispatch\n",
      "    return self.dispatch_func(func_name, gpu_func, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"base.pyx\", line 764, in cuml.internals.base.UniversalBase.dispatch_func\n",
      "  File \"randomforestclassifier.pyx\", line 648, in cuml.ensemble.randomforestclassifier.RandomForestClassifier.predict\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"randomforest_common.pyx\", line 424, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"fil.pyx\", line 1105, in cuml.fil.fil.ForestInference.load_using_treelite_handle\n",
      "  File \"fil.pyx\", line 572, in cuml.fil.fil.ForestInference_impl.load_using_treelite_handle\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/jvcha/miniconda3/envs/rapids-25.02/include/rmm/mr/device/cuda_memory_resource.hpp\n",
      "\n",
      "  warnings.warn(\n",
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/base.py\", line 572, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_4772/1199548088.py\", line 39, in predict\n",
      "    preds = self.estimator.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/nvtx/nvtx.py\", line 122, in inner\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 416, in dispatch\n",
      "    return self.dispatch_func(func_name, gpu_func, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"base.pyx\", line 764, in cuml.internals.base.UniversalBase.dispatch_func\n",
      "  File \"randomforestclassifier.pyx\", line 648, in cuml.ensemble.randomforestclassifier.RandomForestClassifier.predict\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"randomforest_common.pyx\", line 424, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"fil.pyx\", line 1105, in cuml.fil.fil.ForestInference.load_using_treelite_handle\n",
      "  File \"fil.pyx\", line 572, in cuml.fil.fil.ForestInference_impl.load_using_treelite_handle\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/jvcha/miniconda3/envs/rapids-25.02/include/rmm/mr/device/cuda_memory_resource.hpp\n",
      "\n",
      "  warnings.warn(\n",
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/base.py\", line 572, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_4772/1199548088.py\", line 39, in predict\n",
      "    preds = self.estimator.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/nvtx/nvtx.py\", line 122, in inner\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 416, in dispatch\n",
      "    return self.dispatch_func(func_name, gpu_func, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"base.pyx\", line 764, in cuml.internals.base.UniversalBase.dispatch_func\n",
      "  File \"randomforestclassifier.pyx\", line 648, in cuml.ensemble.randomforestclassifier.RandomForestClassifier.predict\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"randomforest_common.pyx\", line 424, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"fil.pyx\", line 1105, in cuml.fil.fil.ForestInference.load_using_treelite_handle\n",
      "  File \"fil.pyx\", line 572, in cuml.fil.fil.ForestInference_impl.load_using_treelite_handle\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/jvcha/miniconda3/envs/rapids-25.02/include/rmm/mr/device/cuda_memory_resource.hpp\n",
      "\n",
      "  warnings.warn(\n",
      "/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 472, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/base.py\", line 572, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_4772/1199548088.py\", line 39, in predict\n",
      "    preds = self.estimator.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/nvtx/nvtx.py\", line 122, in inner\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 416, in dispatch\n",
      "    return self.dispatch_func(func_name, gpu_func, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"base.pyx\", line 764, in cuml.internals.base.UniversalBase.dispatch_func\n",
      "  File \"randomforestclassifier.pyx\", line 648, in cuml.ensemble.randomforestclassifier.RandomForestClassifier.predict\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 193, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"randomforest_common.pyx\", line 424, in cuml.ensemble.randomforest_common.BaseRandomForestModel._predict_model_on_gpu\n",
      "  File \"/home/jvcha/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/cuml/internals/api_decorators.py\", line 195, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"fil.pyx\", line 1105, in cuml.fil.fil.ForestInference.load_using_treelite_handle\n",
      "  File \"fil.pyx\", line 572, in cuml.fil.fil.ForestInference_impl.load_using_treelite_handle\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/jvcha/miniconda3/envs/rapids-25.02/include/rmm/mr/device/cuda_memory_resource.hpp\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "recall_scorer = make_scorer(recall_score, average='macro')\n",
    "recall_scores = []\n",
    "best_params_list = []\n",
    "\n",
    "class cuMLWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=185, max_depth=15, min_samples_leaf=4, max_features='log2', bootstrap=True, random_state=42, n_streams=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.random_state = random_state\n",
    "        self.n_streams=n_streams\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = cudf.DataFrame(X)\n",
    "        if isinstance(y, np.ndarray):\n",
    "            y = cudf.Series(y)\n",
    "        self.estimator = cuRFClassifier(n_estimators=self.n_estimators,\n",
    "                                        max_depth=self.max_depth,\n",
    "                                        random_state=self.random_state,\n",
    "                                        min_samples_leaf=self.min_samples_leaf,\n",
    "                                        max_features=self.max_features,\n",
    "                                        bootstrap=self.bootstrap,\n",
    "                                        n_streams=1,\n",
    "                                       )\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = cudf.DataFrame(X)\n",
    "        preds = self.estimator.predict(X)\n",
    "        return preds.to_array() if hasattr(preds, 'to_array') else preds    \n",
    "        \n",
    "param_space = {\n",
    "        'n_estimators': [100, 125, 150, 175, 200],\n",
    "        'max_depth': [10, 15, 20],\n",
    "        'min_samples_leaf': [1, 2, 3, 4],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'bootstrap': [True, False],\n",
    "        'n_streams': [1, 2, 4],\n",
    "        }\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    X_train = split['X_train_imputed']\n",
    "    y_train = split['y_train']\n",
    "    X_test = split['X_test']\n",
    "    y_test = split['y_test']\n",
    "    \n",
    "    gridsearch_cv = GridSearchCV(\n",
    "        estimator=cuMLWrapper(random_state=42),\n",
    "        param_grid=param_space,\n",
    "        cv=5,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    gridsearch_cv.fit(X_train, y_train)\n",
    "    best_params_list.append(gridsearch_cv.best_params_)\n",
    "    \n",
    "    predictions = gridsearch_cv.predict(X_test)\n",
    "    best_recall = recall_score(y_test, predictions, average='macro')\n",
    "    recall_scores.append(best_recall)\n",
    "    print(f\"Split {i+1} - Best Parameters: {gridsearch_cv.best_params_}, Recall: {best_recall:.3f}\")\n",
    "\n",
    "avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "print(f\"\\nOverall Average Recall: {avg_recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2dd375-f9e7-432d-af7d-1ea610777df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
